{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "import sys, os\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "# gpuid = 0\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']=str(gpuid)\n",
    "import torch\n",
    "dev = torch.device(\"cuda\")\n",
    "# torch.cuda.set_device(dev)\n",
    "import torch.optim as optim\n",
    "from torch.distributions import MultivariateNormal\n",
    "from torch.distributions import Normal\n",
    "# change the root directory for this notebook\n",
    "root_dir = '/global/cfs/cdirs/lsst/www/shivamp/AR_NPE/'\n",
    "os.chdir(root_dir)\n",
    "\n",
    "import sys, os\n",
    "from nf.combined_models import COMBINED_Model\n",
    "from nf.all_models import *\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ji = 0\n",
    "ns_d=256\n",
    "nb = 8\n",
    "nax = ns_d//nb\n",
    "nf = 3\n",
    "nc = 3\n",
    "# z=127 is the initial condition\n",
    "z_all = [0, 0.5, 127]\n",
    "# open the density files for each z and stack along the 2nd axis\n",
    "df_d0 = np.load('/pscratch/sd/s/spandey/quijote/Snapshot_fid/Snapshot_fid_density/' + str(ji) + '/df_m_' + str(ns_d) + '_nbatch=' + str(nb) + '_nfilter=' + str(nf) + '_ncnn=' + str(nc) + '_CIC_z=0_subvol.npy')\n",
    "df_d_all = np.zeros((df_d0.shape[0], len(z_all), df_d0.shape[1], df_d0.shape[2], df_d0.shape[3]))\n",
    "for iz, z in enumerate(z_all):\n",
    "    df_d_all[:, iz, ...] = np.load('/pscratch/sd/s/spandey/quijote/Snapshot_fid/Snapshot_fid_density/0/df_m_' + str(ns_d) + '_nbatch=' + str(nb) + '_nfilter=' + str(nf) + '_ncnn=' + str(nc) + '_CIC_z=' + str(z) + '_subvol.npy')\n",
    "\n",
    "# open the halo information files. These can have a different nside\n",
    "ns_h = 128\n",
    "df_h = pk.load(open('/pscratch/sd/s/spandey/quijote/Snapshot_fid/Snapshot_fid_density/' + str(ji) + '/halo_data_dict_' + str(ns_h) + '.pk','rb'))\n",
    "# This has information on the halo mass for all the halos in the voxel\n",
    "df_Mh_all = df_h['M_halos']\n",
    "# This has information on the number of halos in the voxel\n",
    "df_Nh = df_h['N_halos']\n",
    "\n",
    "# print(df_Mh_all.shape, df_Nh.shape, df_d_all.shape)\n",
    "nsims = 128\n",
    "df_Mh_all = df_Mh_all[:nsims,...]\n",
    "df_Nh = df_Nh[:nsims,...]\n",
    "df_d_all = df_d_all[:nsims,...]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we reshape the number of halos into 2D array of shape number of sub-sim, nvoxels (per sub-sim)\n",
    "# Note that the number of sub-sim = nb**3\n",
    "N_halos_all = df_Nh.reshape((df_Nh.shape[0], df_Nh.shape[1]*df_Nh.shape[2]*df_Nh.shape[3]))\n",
    "\n",
    "# Do the same for the halo mass\n",
    "M_halos_all = df_Mh_all.reshape((df_Mh_all.shape[0], df_Mh_all.shape[1]*df_Mh_all.shape[2]*df_Mh_all.shape[3], df_Mh_all.shape[4]))\n",
    "\n",
    "# Sort the halo mass in descending order\n",
    "M_halos_all_sort = np.flip(np.sort(M_halos_all, axis=-1), axis=-1)\n",
    "# Scale the halo masses to be between 0 and 1\n",
    "Mmin, Mmax = 13.1, 16.0\n",
    "M_halos_all_sort_norm = (M_halos_all_sort - Mmin) / (Mmax - Mmin)\n",
    "\n",
    "# If the halo mass is negative, set it to some small value close to zero\n",
    "ind_neg = np.where(M_halos_all_sort_norm < 0)\n",
    "M_halos_all_sort_norm[ind_neg] = 1e-4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M_halos_all_sort_norm = M_halos_all_sort_norm[:,:,:4]\n",
    "# M_halos_all_sort_norm.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a mask for the halo mass matrix. The mask is 1 in the last axis corresponding to number of halos in that voxel\n",
    "mask_all = np.zeros((N_halos_all.shape[0], N_halos_all.shape[1], M_halos_all_sort.shape[-1]))\n",
    "idx = np.arange(M_halos_all_sort.shape[-1])[None,None,:]\n",
    "mask_all[np.arange(N_halos_all.shape[0])[:,None,None], np.arange(N_halos_all.shape[1])[None,:,None], idx] = (idx < N_halos_all[...,None])\n",
    "\n",
    "# Also create a mask for mass difference. This is 1 if the halo more than one halo is present and 0 if it is not\n",
    "N_halos_diff = N_halos_all - 1\n",
    "N_halos_diff[N_halos_diff < 0] = 0\n",
    "mask_M_diff = np.zeros((N_halos_all.shape[0], N_halos_all.shape[1], M_halos_all_sort_norm.shape[-1]-1))\n",
    "idx = np.arange(M_halos_all_sort_norm.shape[-1]-1)[None,None,:]\n",
    "mask_M_diff[np.arange(N_halos_all.shape[0])[:,None,None], np.arange(N_halos_all.shape[1])[None,:,None], idx] = (idx < N_halos_diff[...,None])\n",
    "\n",
    "mask_M1 = mask_all[:, :, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 4096) (128, 4096) (128, 4096, 9)\n"
     ]
    }
   ],
   "source": [
    "# Heavist halo mass in each voxel\n",
    "M1_halos_all_norm = M_halos_all_sort_norm[..., 0]\n",
    "\n",
    "# Take the rest of the halo masses and create a diff array\n",
    "M_diff_halos_all_norm = M_halos_all_sort_norm[..., :-1] - M_halos_all_sort_norm[..., 1:]\n",
    "# M_diff_halos_all_norm = M_halos_all_sort_norm[..., 1:]\n",
    "\n",
    "# Now we create a mask for the halo masses. This is needed for the loss function\n",
    "M_diff_halos_all_norm_masked = M_diff_halos_all_norm * mask_M_diff\n",
    "\n",
    "print(N_halos_all.shape, M1_halos_all_norm.shape, M_diff_halos_all_norm_masked.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 4096)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pl.figure()\n",
    "# _ = pl.hist(M_diff_halos_all_norm[:,0])\n",
    "# print(mask_M1.shape, nax, df_d_all.shape, df_Nh.shape)\n",
    "# (128//8)**3\n",
    "# N_halos_all.shape\n",
    "Nhalo_train_mg.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 4096) (128, 4096, 1)\n"
     ]
    }
   ],
   "source": [
    "Nmax = int(np.amax(N_halos_all))\n",
    "mu_all = np.arange(Nmax + 1) + 1\n",
    "sig_all = 0.05 * np.ones_like(mu_all)\n",
    "Nhalo_train_mg = sig_all[0] * np.random.randn(N_halos_all.shape[0], N_halos_all.shape[1]) + (N_halos_all) + 1\n",
    "Nhalo_train_mg_arr = Nhalo_train_mg[...,np.newaxis]\n",
    "ngauss_Nhalo = Nmax + 1\n",
    "\n",
    "print(Nhalo_train_mg.shape, Nhalo_train_mg_arr.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim_MAF = 5\n",
    "learning_rate = 0.01\n",
    "nflows_M1_NSF = 5\n",
    "ngauss_M1 = 5\n",
    "changelr = False\n",
    "ksize = nf\n",
    "ninp = df_d_all.shape[1]\n",
    "nfeature_cnn = 4\n",
    "nout_cnn = 4*nfeature_cnn\n",
    "# num_cond = nout_cnn + ninp\n",
    "num_cond = nout_cnn\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand_mat = np.random.rand(100,100)\n",
    "# # rand_mat.shape\n",
    "# np.pad(rand_mat, 0, 'wrap').shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169\n"
     ]
    }
   ],
   "source": [
    "model_Ntot = SumGaussModel(\n",
    "    hidden_dim=hidden_dim_MAF,\n",
    "    num_cond=num_cond,\n",
    "    ngauss=ngauss_Nhalo,\n",
    "    mu_all=mu_all,\n",
    "    sig_all=sig_all\n",
    "    )\n",
    "model_Ntot.to(dev)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model_Ntot.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166\n"
     ]
    }
   ],
   "source": [
    "model_M1 = NSF_M1_CNNcond(K=5, B=3, \n",
    "                       hidden_dim = hidden_dim_MAF,\n",
    "                       num_cond=num_cond+1,nflows=nflows_M1_NSF,\n",
    "                      base_dist=\"gumbel\", mu_pos=False)    \n",
    "\n",
    "model_M1.to(dev)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model_M1.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 4096, 9)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_diff_halos_all_norm_masked.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13793\n"
     ]
    }
   ],
   "source": [
    "# nflow = 3\n",
    "nflows_Mdiff_NSF = 6\n",
    "nsim, nvox_b, ndim_diff= M_diff_halos_all_norm_masked.shape[0], M_diff_halos_all_norm_masked.shape[1], M_diff_halos_all_norm_masked.shape[2]\n",
    "# base_dist = 'halfgauss'\n",
    "base_dist = 'gumbel'\n",
    "# base_dist = 'weibull'\n",
    "model_Mdiff = NSF_Mdiff_CNNcond(dim=ndim_diff,K=5, B=3, \n",
    "                       hidden_dim = hidden_dim_MAF,\n",
    "                       num_cond=num_cond+2,nflows=nflows_Mdiff_NSF,\n",
    "                      base_dist=base_dist, mu_pos=True)    \n",
    "model_Mdiff.to(dev)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model_Mdiff.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# flows_Mdiff = []\n",
    "# for _ in range(nflow):\n",
    "#     flow_ji = MAF_CNN_cond(dim=ndim_diff, hidden_dim=hidden_dim_MAF, num_cond=num_cond + 2)\n",
    "#     flow_ji.to(dev)\n",
    "#     flows_Mdiff.append(flow_ji)\n",
    "    \n",
    "# # prior = MultivariateNormal(torch.zeros(ndim_diff), torch.eye(ndim_diff))\n",
    "# # prior = prior.to('cuda')\n",
    "# priors_all = []\n",
    "# for _ in range(ndim_diff):\n",
    "#     norm_ji = Normal(torch.tensor([0.0], device='cuda'), torch.tensor([1.0], device='cuda'))\n",
    "#     # norm_ji = norm_ji.to('cuda')\n",
    "#     priors_all.append(norm_ji)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# num_cond+2\n",
    "# ndim_diff\n",
    "# model_Mdiff.layers_all_dim\n",
    "# df_Mh_all.shape\n",
    "# df_Mh_all.shape[-1]\n",
    "# nsim, nvox_b, ndim_diff\n",
    "# 11072 + 328+554+119\n",
    "# model_Mdiff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = ndim_diff+1\n",
    "model = COMBINED_Model(\n",
    "        # priors_all,\n",
    "        None,\n",
    "        # flows_Mdiff,\n",
    "        model_Mdiff,\n",
    "        # None,\n",
    "        model_M1,\n",
    "        # None,\n",
    "        model_Ntot,\n",
    "        ndim,\n",
    "        ksize,\n",
    "        ns_d,\n",
    "        ns_h,\n",
    "        nb,\n",
    "        ninp,\n",
    "        nfeature_cnn,\n",
    "        nout_cnn,\n",
    "        # layers_types=['cnn', 'res', 'res', 'res'],\n",
    "        # layers_types=['cnn', 'res'],    \n",
    "        layers_types=['cnn', 'res'],    \n",
    "        act='tanh',\n",
    "        padding='valid',\n",
    "        sep_Ntot_cond=True,\n",
    "        sep_M1_cond=True,\n",
    "        sep_Mdiff_cond=True,\n",
    "        train_Ntot=True,\n",
    "        train_M1=True,\n",
    "        train_Mdiff=True\n",
    "    )\n",
    "\n",
    "model.to(dev)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_all_it = []\n",
    "loss_min = 1e20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list(model.parameters())\n",
    "# model.conv_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15168\n",
      "13793\n",
      "1166\n",
      "169\n",
      "30296\n"
     ]
    }
   ],
   "source": [
    "# ninp \n",
    "# len(priors_all)\n",
    "# print(next(model.parameters()).is_cuda)\n",
    "# model.conv_layers\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.conv_layers.parameters())\n",
    "params_cnn = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params_cnn)\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model_Mdiff.parameters())\n",
    "params_Mdiff = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params_Mdiff)\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model_M1.parameters())\n",
    "params_M1 = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params_M1)\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model_Ntot.parameters())\n",
    "params_Ntot = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params_Ntot)\n",
    "\n",
    "\n",
    "print(params_cnn + params_Mdiff + params_M1 + params_Ntot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33056\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524288, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Nhalo_train_mg_arr.reshape(Nhalo_train_mg_arr.shape[0]*Nhalo_train_mg_arr.shape[1], 1)).shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cond_tensor.to('cuda')\n",
    "# # dev\n",
    "# cond_tensor.device\n",
    "\n",
    "# # cond_tensor.get_device()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 4096, 9)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.amin(X_Mdiff)\n",
    "# mask_M1.shape, mask_M_diff.shape, M1_halos_all_norm.shape, M1_halos_all_norm.shape, Nhalo_train_mg_arr.shape\n",
    "M_diff_halos_all_norm_masked.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:00<20:05,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving bf at: , with loss: -1.3025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 201/2000 [01:46<16:21,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving bf at: , with loss: -1.3026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 401/2000 [03:32<14:31,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving bf at: , with loss: -1.3027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 601/2000 [05:19<12:48,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving bf at: , with loss: -1.3028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 801/2000 [07:05<10:54,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving bf at: , with loss: -1.3029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1001/2000 [08:52<09:08,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving bf at: , with loss: -1.3029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1347/2000 [11:55<05:47,  1.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_114732/3528989995.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmask_tensor_Mdiff_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_tensor_Mdiff_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mmask_tensor_M1_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_tensor_M1_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     loss = model(\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mX_Mdiff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mX_M1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/cfs/cdirs/lsst/www/shivamp/AR_NPE/nf/combined_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_Mdiff, x_M1, x_Ntot, cond_x, mask_Mdiff_truth, mask_M1_truth, Nhalos_truth, use_Ntot_samples, use_M1_samples)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;31m# prior_logprob = torch.sum(prior_logprob_masked, axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;31m# logP_Mdiff = (torch.mean(prior_logprob + log_det))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mlogP_Mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMdiff_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_Mdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond_inp_Mdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_Mdiff_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;31m# print(logP_Ntot.shape, logP_M1.shape, logP_Mdiff.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlogP_Ntot\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogP_M1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogP_Mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/cfs/cdirs/lsst/www/shivamp/AR_NPE/nf/all_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_inp, cond_inp, mask)\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftplus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                 \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconstrained_RQS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail_bound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0mlog_det_all_jd\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mld\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/cfs/cdirs/lsst/www/shivamp/AR_NPE/nf/utils.py\u001b[0m in \u001b[0;36munconstrained_RQS\u001b[0;34m(inputs, unnormalized_widths, unnormalized_heights, unnormalized_derivatives, inverse, tail_bound, min_bin_width, min_bin_height, min_derivative)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mlogabsdet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutside_interval_mask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     outputs[inside_intvl_mask], logabsdet[inside_intvl_mask] = RQS(\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minside_intvl_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0munnormalized_widths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munnormalized_widths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minside_intvl_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "ninit = 0\n",
    "niterations = 2000\n",
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = 0.000075\n",
    "for ito in tqdm(range(niterations)):\n",
    "    optimizer.zero_grad()\n",
    "    it = ito + ninit\n",
    "    # ind_all = np.arange(density_train.shape[0])\n",
    "    # indsel_rand = ind_all\n",
    "    # density_tensor = torch.Tensor(np.array(np.copy(density_train[indsel_rand])))\n",
    "    # cond_tensor = density_tensor\n",
    "    cond_tensor = torch.Tensor(df_d_all)\n",
    "    mask_tensor_M1_train = torch.Tensor(np.copy(mask_M1.reshape(mask_M1.shape[0]*mask_M1.shape[1])))\n",
    "    # mask_tensor_Nhalo_train = torch.Tensor(np.copy(mask_Nhalo_train[indsel_rand, :]))\n",
    "    mask_tensor_Mdiff_train = torch.Tensor(np.copy(mask_M_diff.reshape(mask_M_diff.shape[0]*mask_M_diff.shape[1], mask_M_diff.shape[2])))\n",
    "\n",
    "    # print(N_halos_all.shape, M1_halos_all_norm.shape, M_diff_halos_all_norm_masked.shape)\n",
    "    X_M1 = torch.Tensor(np.copy(M1_halos_all_norm.reshape(M1_halos_all_norm.shape[0]*M1_halos_all_norm.shape[1], 1)))\n",
    "    X_Nhalo = torch.Tensor(np.copy((Nhalo_train_mg_arr.reshape(Nhalo_train_mg_arr.shape[0]*Nhalo_train_mg_arr.shape[1], Nhalo_train_mg_arr.shape[2]))))\n",
    "    X_Mdiff = torch.Tensor(np.copy(M_diff_halos_all_norm_masked.reshape(mask_M_diff.shape[0]*mask_M_diff.shape[1], mask_M_diff.shape[2])))\n",
    "    X_M1 = X_M1.to(dev)\n",
    "    X_Nhalo = X_Nhalo.to(dev)\n",
    "    X_Mdiff = X_Mdiff.to(dev)\n",
    "    cond_tensor = cond_tensor.to(dev)\n",
    "    mask_tensor_Mdiff_train = mask_tensor_Mdiff_train.to(dev)\n",
    "    mask_tensor_M1_train = mask_tensor_M1_train.to(dev)\n",
    "    loss = model(\n",
    "        X_Mdiff,\n",
    "        X_M1,\n",
    "        X_Nhalo,\n",
    "        cond_x=cond_tensor,\n",
    "        mask_Mdiff_truth=mask_tensor_Mdiff_train,\n",
    "        mask_M1_truth=mask_tensor_M1_train,\n",
    "        Nhalos_truth=torch.Tensor(np.copy((N_halos_all.reshape(N_halos_all.shape[0]*N_halos_all.shape[1], 1)))),\n",
    "        use_Ntot_samples=False,\n",
    "        use_M1_samples=False\n",
    "        )\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # loss_all_it.append(float(loss.detach().numpy()))\n",
    "\n",
    "    if (np.mod(it, int(niterations / 10)) == 0) or (it == niterations - 1):\n",
    "        if float(loss.cpu().detach().numpy()) < loss_min:\n",
    "            loss_min = float(loss.cpu().detach().numpy())\n",
    "            # print(loss1.detach().numpy(), loss2.detach().numpy(), loss3.detach().numpy())\n",
    "            print('saving bf at:', ', with loss:', np.round(loss_min, 4))\n",
    "            # print('saving bf at:', it, ', with loss:', np.round(loss_min, 9))\n",
    "            state = {'loss_min': loss_min, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "\n",
    "            torch.save(state, 'FINAL_COMBINED/model_save_ji' + str(ji) + '_nsd' + str(ns_d) + '_nb' + str(nb) + '_nf' + str(nf) + '_nsh' + str(ns_h) + '_nsim' + str(nsims))\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.3024, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_Nhalo.shape\n",
    "# X_Nhalo.shape, X_M1.shape, mask_M1.shape\n",
    "# mask_tensor_M1_train.shape\n",
    "# mask_tensor_Mdiff_train.shape, X_Mdiff.shape\n",
    "loss\n",
    "# mask_tensor_Mdiff_tr?ain\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 38, 38, 38])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_Mdiff\n",
    "cond_tensor.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3705, 0.3580, 0.3665,  ..., 0.0246, 0.0253, 0.0272], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>) tensor([0.5033, 0.4901, 0.5115,  ..., 0.1293, 0.1306, 0.1319], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>)\n",
      "tensor([0.2494, 0.2462, 0.2449,  ..., 0.2431, 0.2401, 0.2484], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>) tensor([0.1817, 0.1755, 0.1738,  ..., 0.1792, 0.1711, 0.1908], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>)\n",
      "tensor([0.6643, 0.6666, 0.6717,  ..., 0.6161, 0.6147, 0.6381], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>) tensor([0.9549, 0.8352, 0.6512,  ..., 0.0712, 0.0829, 0.0706], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>)\n",
      "tensor([0.3017, 0.3043, 0.3032,  ..., 0.2804, 0.2767, 0.2954], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>) tensor([0.0140, 0.0152, 0.0145,  ..., 0.6062, 1.2693, 0.2468], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>)\n",
      "tensor([0.2755, 0.2761, 0.2758,  ..., 0.3718, 0.3812, 0.4035], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>) tensor([0.4567, 0.4540, 0.4579,  ..., 0.5061, 0.5217, 0.5324], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>)\n",
      "tensor([0.6320, 0.6430, 0.6446,  ..., 0.8778, 0.8787, 0.8822], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>) tensor([0.5140, 0.5078, 0.5085,  ..., 0.2389, 0.2391, 0.2340], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>)\n",
      "tensor([0.6463, 0.6458, 0.6445,  ..., 0.6638, 0.6632, 0.6606], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>) tensor([1.0508, 1.0533, 1.0563,  ..., 1.0189, 1.0192, 1.0010], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>)\n",
      "tensor([0.5128, 0.5135, 0.5143,  ..., 0.4895, 0.4895, 0.4979], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>) tensor([1.1385, 1.1347, 1.1319,  ..., 1.1695, 1.1621, 1.1145], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>)\n",
      "tensor([0.4669, 0.4643, 0.4639,  ..., 0.4438, 0.4404, 0.4366], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>) tensor([1.4020, 1.4072, 1.4098,  ..., 1.4573, 1.4650, 1.4869], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>)\n"
     ]
    }
   ],
   "source": [
    "cond_tensor = cond_tensor.to(dev)\n",
    "Ntot_samp, M1_samp, M_diff_samp, mask_tensor_M1_samp, mask_tensor_Mdiff_samp = model.inverse(\n",
    "        cond_x=cond_tensor,\n",
    "        use_truth_Nhalo=False,\n",
    "            use_truth_M1=False,\n",
    "            use_truth_Mdiff=False,\n",
    "            mask_Mdiff_truth=mask_tensor_Mdiff_train,\n",
    "            mask_M1_truth=mask_tensor_M1_train,\n",
    "            Nhalos_truth=X_Nhalo,\n",
    "            M1_truth=X_M1\n",
    "        )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((524288,), (524288,))"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ntot_samp.shape, X_Nhalo[:,0].cpu().detach().numpy().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([524288]), (524288,))"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1_samp.shape, X_M1[:,0].cpu().detach().numpy().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((524288, 9), (524288, 9))"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_diff_samp.cpu().detach().numpy().shape, X_Mdiff.cpu().detach().numpy().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Histogram')"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.figure()\n",
    "_ = pl.hist(Ntot_samp, histtype='step')\n",
    "_ = pl.hist(N_halos_all.reshape(N_halos_all.shape[0]*N_halos_all.shape[1]), histtype='step')\n",
    "# _ = pl.hist(X_Nhalo[:,0].cpu().detach().numpy())\n",
    "pl.yscale('log')\n",
    "pl.xlabel('Nhalo')\n",
    "pl.ylabel('Histogram')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 7, 7, 7])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N_halos_all\n",
    "Ntot_samp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Histogram')"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.figure()\n",
    "indp = (mask_tensor_M1_samp.cpu().detach().numpy()[:,0] > 0)\n",
    "_ = pl.hist(M1_samp.cpu().detach().numpy()[indp], range=(0,1), histtype='step')\n",
    "indp = (mask_tensor_M1_train.cpu().detach().numpy() > 0)\n",
    "_ = pl.hist(X_M1[:,0].cpu().detach().numpy()[indp], range=(0,1))\n",
    "pl.yscale('log')\n",
    "pl.xlabel('M1')\n",
    "pl.ylabel('Histogram')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([524288, 1])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# M_diff_samp.shape\n",
    "mask_tensor_M1_samp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Histogram')"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.figure()\n",
    "ind_M = 5\n",
    "\n",
    "indp = mask_tensor_Mdiff_samp[:, ind_M] > 0\n",
    "_ = pl.hist(M_diff_samp[indp,ind_M].cpu().detach().numpy(), range=(0,0.5), histtype='step')\n",
    "indp = mask_tensor_Mdiff_train[:, ind_M] > 0\n",
    "_ = pl.hist(X_Mdiff[indp,ind_M].cpu().detach().numpy(), range=(0,0.5))\n",
    "\n",
    "\n",
    "# _ = pl.hist(M_diff_samp[:,ind_M].cpu().detach().numpy(), range=(0,1), histtype='step')\n",
    "# _ = pl.hist(X_Mdiff[:,ind_M].cpu().detach().numpy(), range=(0,1))\n",
    "\n",
    "\n",
    "pl.yscale('log')\n",
    "pl.xlabel('M1')\n",
    "pl.ylabel('Histogram')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_Mdiff[:,ind_M]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import HalfNormal, Weibull, Gumbel\n",
    "mu, sig = -0.5421, 0.0679\n",
    "hf = Gumbel(mu, sig)\n",
    "gr = hf.sample([10000])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.9.0",
   "language": "python",
   "name": "pytorch-1.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
